[
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "In my current position I am designing tutorials to help users access and use NEON genetic data, building on the tools in my R package. I am working with colleagues at the National Microbiome Data Collaborative (NMDC) to increase access to these data on the JGI and NMDC data portals. Together we have given workshops on accessing NEON data and I wrote an R tutorial to help users begin to integrate the metagenome data across different NEON products.\nIn my previous position as bioinformatician in the Department of Anatomy at the University of Otago, I ran a bioinformatics help session in the Anatomy department. Most of the material from these sessions is available on the hacky hour webpage. These sessions range from getting started writing scripts to some guidelines on troubleshooting command line errors. Over the course of teaching I added some additional reference material to the site. The more advanced workshops generally comprised a combination of live coding and practical problem solving.\nAs part of the Otago Carpentries group (main link) I have helped put on frequent workshops and training sessions. Here is a link to past workshops, which contain a great deal of content. The Bioinformatics Spring School, held in November, 2020, provides a framework for future large events through Otago Carpentries. It consisted of both basic lessons and specific training in several areas, such as gene expression and population genetics.\nI have taught several workshops on environmental DNA (eDNA), and organised an eDNA conference attended by researchers from throughout New Zealand and the Pacific region. As part of the conference, I taught a one-day workshop on metabarcoding, which included an optional day for beginners to learn the basics of the command line and R. I continued to develop the content for this course and taught it several times."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Bioinformatic Work",
    "section": "",
    "text": "This webpage is an overview of my bioinformatic work. I approach bioinformatics with a creative, problem-solving approach for diverse research questions. I have developed bioinformatic pipelines for a wide range of research projects, including population and phylogenetic studies, metagenomics, epigenetics, comparative genomics, transcriptomics, and gene expression of both host and pathogens. To address this diversity of research themes I strive to create tools that are flexible and can be applied across multiple projects. As a bioinformatician with a background in laboratory genetics, I understand the challenges that my colleagues face when approaching genomic data. I always work to create bioinformatic pipelines and workflows that allow all researchers on a project to explore the data."
  },
  {
    "objectID": "index.html#the-building-blocks-of-bioinformatics",
    "href": "index.html#the-building-blocks-of-bioinformatics",
    "title": "My Bioinformatic Work",
    "section": "The building blocks of bioinformatics",
    "text": "The building blocks of bioinformatics\nIn my bioinformatics work I take a flexible approach to elucidate biological systems. I design dynamic analytic pipelines to fit the appropriate research questions while maintaining fundamental programmatic building blocks across all projects. To then convey the results of such complex biological interactions it is necessary to have good communications among all members of the research team. An essential component of my role is to train and teach these analytic building blocks and present research outputs visually and interactively.\nI approach teaching with the same concepts. I ran a bioinformatics help session at the Department of Anatomy at the University of Otago, New Zealand. For a description of what I consider the bioinformatic building blocks see this page on the help session web page.\n\n\n\n\n\n\n\n(a) alignment\n\n\n\n\n\n\n\n(b) clustering\n\n\n\n\nFigure 1: Basic processes of bioinformatics"
  },
  {
    "objectID": "analyses.html",
    "href": "analyses.html",
    "title": "Analyses",
    "section": "",
    "text": "This page includes some milestones of my data analysis"
  },
  {
    "objectID": "analyses.html#microbe-community-taxonomy-data-product",
    "href": "analyses.html#microbe-community-taxonomy-data-product",
    "title": "Analyses",
    "section": "Microbe Community Taxonomy data product",
    "text": "Microbe Community Taxonomy data product\nThe older NEON product ‘Microbe Community Composition’ needed updating, so I overhauled it and created the new version: ‘Microbe Community Taxonomy’. The new version allows for comparison of all samples across years and sites.\nTo accomplish this I developed a pipeline to process NEON amplicon sequence data using multiple approaches and ran them using Docker images in a Kubernetes engine on the NEON node of the Google Cloud Platform. The results of this analysis comprise over 15000 samples collected over seven years (2018-2024) across all 81 NEON field sites, with thousands of new samples to be sequenced each year. Perhaps more challenging than running the data through the pipeline was organizing the results so as to be flexible for end users to download any number of samples from any year. This required devising new systems to substitute for the sometimes overwhelmed data structures of the existing software.\n\n\n\nMCT data product on NEON data portal"
  },
  {
    "objectID": "analyses.html#population-genomics-from-environmental-data",
    "href": "analyses.html#population-genomics-from-environmental-data",
    "title": "Analyses",
    "section": "Population genomics from environmental data",
    "text": "Population genomics from environmental data\nThe code (on this repository) was developed for a PhD project at the University of Otago (preprint here). The student collected water from bays and harbours around New Zealand that had populations of fur seals. DNA was extracted from the water samples and probed with hybrid capture baits designed from fur seal mitochondrion. I designed some scripts to identify fur seal haplotypes from mitochondrial genes. Because the samples were environmental, I did not use assembly to construct haplotypes but instead devised a script to match the haplotype of each sequence separately.\n\n\n\nfur seal"
  },
  {
    "objectID": "analyses.html#metabarcoding-pipeline-example",
    "href": "analyses.html#metabarcoding-pipeline-example",
    "title": "Analyses",
    "section": "Metabarcoding pipeline example",
    "text": "Metabarcoding pipeline example\nThis repository is an example of an amplicon sequence pipeline I used for a recent paper. I have explored multiple approaches to metabarcoding, in both my research and teaching. See the Teaching page for examples of teaching different approaches."
  },
  {
    "objectID": "basicTools.html",
    "href": "basicTools.html",
    "title": "Bioinformatic Tools",
    "section": "",
    "text": "Here are some bioinformatic tools I have created for large and small research projects"
  },
  {
    "objectID": "basicTools.html#basic-tools",
    "href": "basicTools.html#basic-tools",
    "title": "Bioinformatic Tools",
    "section": "Basic Tools",
    "text": "Basic Tools\nHere are some examples of basic bioinformatic tools I have written (some were written in Python 2).\nIn my repository seq_tools I have put a few scripts that I use for manipulating DNA sequence data. A useful one is seq_extractor.py, that I use to extract a subset of sequences from a larger fasta file, from a file with a list of sequence ids. The page contains example files. I have used this script a great deal, as I find I often want to take a subset of sequences from a file (e.g. differentially expressed transcripts from a transcriptome file). I often use it interactively in Jupyter Notebook. I have extracted sequences from very large files (e.g. spruce genome, 8 Gb with about 12 million scaffolds). The speed was tremendously improved when I converted the list of sequence ids to a Python set (from hours to minutes). Just goes to show that data structures matter!\nMy repository genbanking contains a couple of scripts for parsing NCBI files, including BLAST files and Genbank format sequence files. I use these kinds of files so often that I put together some general tools for parsing and extracting information from them. I describe two below, but I will be adding more."
  },
  {
    "objectID": "basicTools.html#jupyter-notebooks",
    "href": "basicTools.html#jupyter-notebooks",
    "title": "Bioinformatic Tools",
    "section": "Jupyter notebooks",
    "text": "Jupyter notebooks\nI do most of my Python development using Jupyter notebooks. I have started to export the notebooks in HTML format so I can reference them easily. Here is a link to the index page.\nHere are a couple of notebooks on deriving haplotypes from sequence data:\nfind haplotypes\nextract haplotypes from bam file\nFor mapping to genomes, I wrote some code to work with GFF files:\nFinding overlapping ranges between two gff files\nChange values in column of gff\nFor converting tables\nCreate reference sequence from BLAST results\nConvert Obitools tab to Qiime2"
  },
  {
    "objectID": "myPackages.html",
    "href": "myPackages.html",
    "title": "Major Projects",
    "section": "",
    "text": "I am a co-developer on the Python program Crabs. This program creates and curates reference databases from downloaded sequence data, including NCBI, EMBL, and curated databases such as UNITE. The reference databases from Crabs can be used to prepare reference databases for amplicon sequencing work. It features both insilico PCR and alignment-based methods to find target sequences in online databases. There are also some summary figures that can be generated to evaluate diversity of targets and primers. I also created a Docker image for this program (quay.io/swordfish/crabs).\n\n\n\ndiversity figure from Crabs"
  },
  {
    "objectID": "myPackages.html#phyloneon",
    "href": "myPackages.html#phyloneon",
    "title": "Major Projects",
    "section": "phyloNEON",
    "text": "phyloNEON\nI have created an R package, phyloNEON, to help researchers access and use NEON genetic data. A database included in the package contains all NEON metagenome samples that have been analyzed through the JGI pipeline with extensive metadata to assist in searching. I have written functions that help users search this database and access taxonomic and functional genomic data for each sample.\nFor the processed amplicon sequence data (see analyses), phyloNEON also includes functions to convert downloaded NEON metabarcoding data to the phyloseq package format.\nThis package is being continually developed, with plans to include tools to help researchers access and utilize all NEON genetic data. For some tools they have utility for non-NEON genetic data.\n\n\n\nNEON sample on JGI portal"
  }
]